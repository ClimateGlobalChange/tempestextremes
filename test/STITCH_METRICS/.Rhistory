cat(sprintf("latname<-\"%s\"\n",latname))
cat(sprintf("lonname<-\"%s\"\n",lonname))
cat(sprintf("transformto180<-%s\n",TF180))
cat(sprintf("transformto360<-%s\n",TF360))
cat(sprintf("minlat<-%f\n",minlat))
cat(sprintf("maxlat<-%f\n",maxlat))
cat(sprintf("minlon<-%f\n",minlon))
cat(sprintf("maxlon<-%f\n",maxlon))
cat("minlev<-\"\"\n")
cat("maxlev<-\"\"\n")
cat(sprintf("regridto1degree<-%s\n",TFregrid))
cat("\n")
cat("#INTERCOMPARE SPECS----------\n")
cat(sprintf("nrun_ic<-%d\n",numcombos))
cat(sprintf("table_file_1<-c(\"%s\")\n",table1_string))
cat(sprintf("table_file_2<-c(\"%s\")\n",table2_string))
cat(sprintf("df_name_1<-\"%s\"\n",df_icname))
cat(sprintf("df_name_2<-\"%s\"\n",df_icname))
cat("regrid<-FALSE\n")
cat(sprintf("blob_file_1<-c(\"%s\")\n",blob1_string))
cat(sprintf("var_name_1<-c(\"%s\")\n",var1_string))
cat(sprintf("blob_file_2<-c(\"%s\")\n",blob2_string))
cat(sprintf("var_name_2<-c(\"%s\")\n",var2_string))
cat(sprintf("rfn_ps<-c(\"%s\")\n",icname_string))
cat(sprintf("txt_overlaps<-c(\"%s\")\n",txtico_string))
cat(sprintf("txt_ps<-c(\"%s\")\n",txticp_string))
cat("\n")
cat("#REPORT SPECS----------\n")
cat(sprintf("output_name<-\"%s\"\n",reportname_string))
cat(sprintf("metadata_datasets<-\"%s\"\n",metadata_datasets))
cat(sprintf("Varnames<-c(\"%s\")\n",Varnames_string))
cat(sprintf("nyears<-%d\n",nyears))
cat(sprintf("mergefiles<-c(\"%s\")\n",summ_string))
cat(sprintf("summfiles<-c(\"%s\")\n",rdata_summstring))
cat(sprintf("blobfiles<-c(\"%s\")\n",rdata_blobstring))
cat(sprintf("blobname<-c(\"%s\")\n",varvec_string))
cat(sprintf("icfiles<-c(\"%s\")\n",icname_string))
sink()
#Autocorrelation
#Have: lat/lon matrix
require(reshape2)
require(akima)
deg2rad<-function(deg) {
return(deg * (pi/180))
}
getDistanceFromLatLonInKm<-function(lat1,lon1,lat2,lon2) {
R = 6371;
dLat = deg2rad(lat2-lat1)
dLon = deg2rad(lon2-lon1)
a = sin(dLat/2) * sin(dLat/2) +
cos(deg2rad(lat1)) * cos(deg2rad(lat2)) *
sin(dLon/2) * sin(dLon/2)
b = 2 * atan2(sqrt(a), sqrt(1-a))
d = R * b
return(d)
}
pearson_arr<-function(arr1,arr2,lat1,lat2,lon1,lon2,interp=FALSE,centered=FALSE){
longdata1<-melt(arr1,value.name="V1")
longdata1$lon<-lon1[longdata1$Var1]
longdata1$lat<-lat1[longdata1$Var2]
if (interp==TRUE){
arr2_analyze<-linint(arr2,lat2,lon2,lat1,lon1)
}else{
arr2_analyze<-arr2
}
longdata2<-melt(arr2_analyze,value.name="V2")
longdata2$lon<-lon1[longdata2$Var1]
longdata2$lat<-lat1[longdata2$Var2]
longdata<-merge(longdata1,longdata2,by=c("lon","lat"))
#Create a cosine latitude column
longdata$coslat<-cos(longdata$lat*pi/180)
longdata$cosV1<-longdata$V1*longdata$coslat
longdata$cosV2<-longdata$V2*longdata$coslat
Vproduct<-longdata$cosV1*longdata$cosV2
V1bar<-mean(longdata$cosV1)
V2bar<-mean(longdata$cosV2)
V1diff<-longdata$cosV1-V1bar
V2diff<-longdata$cosV2-V2bar
VdiffProduct<-V1diff*V2diff
if (centered==TRUE){
r<-sum(VdiffProduct)/sqrt(sum(V1diff*V1diff)*sum(V2diff*V2diff))
}else{
r<-sum(Vproduct)/sqrt(sum(longdata$cosV1*longdata$cosV1)*sum(longdata$cosV2*longdata$cosV2))
}
return(r)
}
load("~/block_r_data/new_data/ERA_data/ERA_NP_pv_z_ghg_block_data.RData")
load("~/BLOBSTATS_FILES/DJF_NP/DJF_NP_ERA_blobdata.RData")
z_avg<-apply(z_anom,mean,MARGIN = c(1,2))
pv_avg<-apply(pv_anom,mean,MARGIN=c(1,2))
df<-(length(as.vector(z_avg)))-2
corr.test<-pearson_arr(z_avg,pv_avg,lat_axis,lon_axis,lat_axis,lon_axis)
library(spdep)
#Calculate the distance
xy<-expand.grid(lon_axis[1:5],lat_axis;1:5)
xyz<-cbind(xy,as.vector(z_avg[1:5,1:5]))
colnames(xyz)<-c("x","y","z")
coordinates(xyz)<-c("x","y")
xy<-expand.grid(lon_axis[1:5],lat_axis[1:5])
xyz<-cbind(xy,as.vector(z_avg[1:5,1:5]))
colnames(xyz)<-c("x","y","z")
coordinates(xyz)<-c("x","y")
nlist <- dnearneigh(xyz, d1=0,d2=5,longlat = T)
xy<-expand.grid(lon_axis[1:5],lat_axis[1:5])
xyz<-cbind(xy,as.vector(z_avg[1:5,1:5]))
colnames(xyz)<-c("x","y","z")
nlist <- dnearneigh(xyz, d1=0,d2=5,longlat = T)
?dnearneigh
nlist <- dnearneigh(xy, d1=0,d2=5,longlat = T)
xy
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=5,longlat = T)
head(nlist)
nlist
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=1000,longlat = T)
nlist
names(nlist)
nlist
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=5000,longlat = T)
nlist
#Calculate the distance
xy<-expand.grid(lon_axis[1:10],lat_axis[1:10])
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=5000,longlat = T)
nlist
sp.correlogram(nlist,as.vector(z_avg[1:10,1:10]))
sp.correlogram(nlist,as.vector(z_avg[1:10,1:10]),maxlag=2)
sp.correlogram(nlist,as.vector(z_avg[1:10,1:10]),order=2)
sp.correlogram(nlist,as.vector(z_avg[1:10,1:10]),order=3)
sp.correlogram(nlist,as.vector(z_avg[1:10,1:10]),order=1)
?sp.correlogram
xy<-expand.grid(lon_axis,lat_axis)
#xyz<-cbind(xy,as.vector(z_avg[1:10,1:10]))
#colnames(xyz)<-c("x","y","z")
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=3000,longlat = T)
nlist
I.d <- sp.correlogram(nlist, as.vector(z_avg), order = 15,
method = "I", style = "W", randomisation = TRUE)
I.d <- sp.correlogram(nlist, as.vector(z_avg), order = 2,
method = "I", style = "W")#, randomisation = TRUE)
source('~/.active-rstudio-document', echo=TRUE)
z_avg<-apply(z_anom,mean,MARGIN = c(1,2))
pv_avg<-apply(pv_anom,mean,MARGIN=c(1,2))
corr.test<-pearson_arr(z_avg,pv_avg,lat_axis,lon_axis,lat_axis,lon_axis)
library(spdep)
#Calculate the distance
xy<-expand.grid(lon_axis,lat_axis)
#xyz<-cbind(xy,as.vector(z_avg[1:10,1:10]))
#colnames(xyz)<-c("x","y","z")
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=300,longlat = T)
I.d <- sp.correlogram(nlist, as.vector(z_avg), order = 20,
method = "I", style = "W")#, randomisation = TRUE)
load("~/BLOBSTATS_FILES/DJF_NP/DJF_NP_ERA_blobdata.RData")
z_avg<-apply(z_anom,mean,MARGIN = c(1,2))
pv_avg<-apply(pv_anom,mean,MARGIN=c(1,2))
corr.test<-pearson_arr(z_avg,pv_avg,lat_axis,lon_axis,lat_axis,lon_axis)
library(spdep)
#Calculate the distance
xy<-expand.grid(lon_axis,lat_axis)
#xyz<-cbind(xy,as.vector(z_avg[1:10,1:10]))
#colnames(xyz)<-c("x","y","z")
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=300,longlat = T)
I.d <- sp.correlogram(nlist, as.vector(z_avg), order = 20,
method = "I", style = "W")#, randomisation = TRUE)
I.d <- sp.correlogram(nlist, as.vector(z_avg), order = 20,
method = "I", style = "W")#, randomisation = TRUE)
nlist
I.d <- sp.correlogram(nlist, as.vector(z_avg), order = 5,
method = "I", style = "W")
I.d
plot(I.d)
names(I.d)
?moran.plot
nw<-nb2listw(nlist)
nw
nrow(nw)
length(as.vector(z_avg))
moran.plot(as.vector(z_avg),nw)
mp<-moran.plot(as.vctor(z_avg,nw)
)
mp<-moran.plot(as.vctor(z_avg),nw)
mp<-moran.plot(as.vector(z_avg),nw)
names(mp)
mp$is.inf
which(rowSums(mp$is.inf) > 0)
inf.mp<-which(rowSums(mp$is.inf) > 0)
moran.plot(as.vector(z_avg),nw,quiet=T)
moran.plot(as.vector(z_avg),nw,labels=F)
sample_rows<-sample(100,seq(1:length(as.vector(z_avg))),replace=F)
dim(nw)
moran.plot(as.vector(z_avg[sample_rows]),nw[sample_rows])
nw
names(nw)
nw
mp$is.inf
plot(I.d)
print(I.d)
cor(z_avg[50,50],z_avg[50,51])
?cor
cor.test(z_avg[50,50],z_avg[50,51])
nw$weights
cor.lag<-lag.listw(nw,as.vector(z_avg))
cor.lat
cor.lag
#spatial weights matrix
wm<-nb2mat(nw,style="B")
#spatial weights matrix
wm<-nb2mat(nw)
#spatial weights matrix
wm<-nb2mat(nlist)
wm
wm[1:5,1:5]
I.d
plot(I.d)
#xyz<-cbind(xy,as.vector(z_avg[1:10,1:10]))
#colnames(xyz)<-c("x","y","z")
nlist <- dnearneigh(as.matrix(xy), d1=0,d2=600,longlat = T)
1-(4*.024)
.904/4
1-(5*.024)
.904/3
.708+.22*.024
.708+.22+.024
1-(2*.024)
a<-"foobar"
?sub
sub("foo","foooo",a)
a2<-c("fooooooo","foo2","foo32")
sub("foo","meow",a2)
source("~/BLOBSTATS_FILES/DJF_NP/DJF_NP_namelist_master_sub.R")
getwd()
setwd("~/tempestextremes/test/STITCH_METRICS/")
require(knitr)
require(markdown)
require(rmarkdown)
require(reshape2)
#Returns in the -180->180 range
lon_convert<-function(lon){
distFrom180=lon-180.
return(ifelse(
distFrom180<0,
lon,
-(180-distFrom180)
))
}
#Returns in the 0->360 range
lon_convert2<-function(lon){
return(ifelse(lon<0,360+lon,lon))
}
#source("~/tempestextremes/test/STITCH_METRICS/namelist_report_JJA_SP.R")
#Generate the title string based on the variables
title_string<-paste("Comparison of blocking data for ",Varnames[1])
for (t in 2:length(Varnames)){
title_string<-paste(title_string, Varnames[t], sep=", ")
}
md_file<-"report_template.Rmd"
avgdata<-data.frame(x=numeric(),y=numeric(),value=numeric(),
VAR=character(),lon=numeric(),lat=numeric())
#Make a list object that will have all of the relevant data
comparison_data<-list()
for (i in 1:length(Varnames)){
comparison_data$varname[i]<-Varnames[i]
#Load the merged table
load(mergefiles[i])
merge_dfname<-sprintf("V%d_merge",i)
assign(merge_dfname,get(df_name))
comparison_data$mergename[i]<-merge_dfname
#load the summary table
load(summfiles[i])
summ_dfname<-sprintf("V%d_summ",i)
assign(summ_dfname,df_summ)
comparison_data$summname[i]<-summ_dfname
#load the blob data
load(blobfiles[i])
assign(sprintf("lat%d",i),lat_axis)
assign(sprintf("lon%d",i),lon_axis)
assign(sprintf("time%d",i),time_format)
assign(sprintf("blob%d",i),get(blobname[i]))
temp_var<-get(sprintf("blob%d",i))
temp_var[which(temp_var>0)]<-1
assign(sprintf("blob%d",i),temp_var)
#average the blob data
avgname<-sprintf("avgblob%d",i)
ablob<-apply(get(sprintf("blob%d",i)),c(1,2),mean)
#Add to the long table for plotting
temp<-melt(ablob,varnames=c("x","y"))
temp$VAR<-rep(Varnames[i],nrow(temp))
temp$lon<-lon_axis[temp$x]
temp$lat<-lat_axis[temp$y]
avgdata<-rbind(avgdata,temp)
assign(avgname,ablob)
}
avgdata$VAR<-factor(avgdata$VAR,levels=c("CMCC-CESM","JRA","MERRA","CFSR","ERA"))
library(kableExtra)
install.packages("kableExtra")
library(kableExtra)
install.packages("xml2")
library(kableExtra)
knitr::opts_chunk$set(echo=FALSE)
require(ggplot2)
require(reshape2)
require(gtable)
require(grid)
nvars<-length(Varnames)
data_table<-data.frame(NULL)
df_merge_all<-data.frame(NULL)
df_summ_all<-data.frame(NULL)
for (i in 1:nvars){
df_summ<-get(sprintf("V%d_summ",i))
df_summ_all<-rbind(df_summ_all,df_summ)
df_merge<-get(sprintf("V%d_merge",i))
df_merge_all<-rbind(df_merge_all,df_merge)
df_dates<-unique(as.Date(df_merge$datehour))
if (exists("resolutions")){
data_table["Spatial resolution",i]<-resolutions[i]
}
data_table["Number of unique blobs",i]<-nrow(df_summ)
data_table["Number of merged blobs",i]<-nrow(df_summ[df_summ$merged=="YES",])
data_table["Maximum blocking frequency",i]<-sprintf("%.4f",max(get(sprintf("avgblob%d",i))))
data_table["Interquartile range of blob centroid latitude",i]<-paste(sprintf("%.2f",quantile(df_merge$centlat,c(0.25,0.75))),collapse=" ")
data_table["Number of blocked days",i]<-length(df_dates)
data_table["Average number of blocked days (divided by number of years)",i]<-sprintf("%.2f",length(df_dates)/nyears)
data_table["Interquartile range of duration (days)",i]<-paste(sprintf("%.2f",quantile(df_summ$duration_days,c(0.25,0.75))),collapse=" ")
data_table["Interquartile range of speed (km/hr)",i]<-paste(sprintf("%.2f",quantile(df_summ$zonal_speed_kph,c(0.25,0.75))),collapse=" ")
data_table["Interquartile range of blob size (10^6 km^2)",i]<-paste(sprintf("%.2f",quantile(df_merge$area_km/(10^6),c(0.25,0.75))),collapse=" ")
}
df_merge_all$var<-factor(df_merge_all$var,levels=Varnames)
df_summ_all$var<-factor(df_summ_all$var,levels=Varnames)
colnames(data_table)<-Varnames
head(data_table)
data_table2<-data_table[,c("CMCC-CESM","JRA","MERRA","CFSR","ERA")]
kable(data_table2)
kable(data_table2,"latex")
set.seed(100000000)
#permutationping!
#Pool the samples and resample
#If the means are the same,
#Make a table for T-test and Wilcoxon
wilcox_mat<-matrix(nrow=nvars,ncol=nvars)
t_mat<-matrix(nrow=nvars,ncol=nvars)
b_mat<-matrix(nrow=nvars,ncol=nvars)
colnames(wilcox_mat)<-Varnames
rownames(wilcox_mat)<-Varnames
colnames(t_mat)<-Varnames
rownames(t_mat)<-Varnames
colnames(b_mat)<-Varnames
rownames(b_mat)<-Varnames
wilcox_table<-NULL
t_table<-NULL
b_table<-NULL
for (m in c("duration_days","zonal_speed_kph")){
df_sum_sub<-df_summ_all[,c("var",m)]
for (i in 1:length(Varnames)){
for (j in 1:length(Varnames)){
if (j>i){
var1<-Varnames[i]
df_sum_sub1<-df_sum_sub[df_sum_sub$var==var1,]
dist1<-df_sum_sub1[,m]
var2<-Varnames[j]
df_sum_sub2<-df_sum_sub[df_sum_sub$var==var2,]
dist2<-df_sum_sub2[,m]
all<-c(dist1,dist2)
ts<-median(dist1)-median(dist2)
k<-1:length(all)
reps<-c()
for (x in 1:5000){
n<-sample(k,size=min(length(dist1),length(dist2)),replace=F)
ps1<-all[n]
ps2<-all[-n]
reps[x]<-median(ps1)-median(ps2)
}
pv<-mean(abs(reps)>=abs(ts))
b_mat[j,i]<-pv
t<-t.test(dist1,dist2)
w<-wilcox.test(dist1,dist2)
wilcox_mat[j,i]<-w$p.value
t_mat[j,i]<-t$p.value
}
}
}
temp<-melt(wilcox_mat,na.rm = T)
temp$metric<-rep(m,nrow(temp))
wilcox_table<-rbind(wilcox_table,temp)
temp<-melt(t_mat,na.rm = T)
temp$metric<-rep(m,nrow(temp))
t_table<-rbind(t_table,temp)
temp<-melt(b_mat,na.rm = T)
temp$metric<-rep(m,nrow(temp))
b_table<-rbind(b_table,temp)
}
df_merge_sub<-df_merge_all[,c("var","area_km")]
for (i in 1:length(Varnames)){
for (j in 1:length(Varnames)){
if (j>i){
var1<-Varnames[i]
df_sum_sub1<-df_merge_sub[df_merge_sub$var==var1,]
dist1<-df_sum_sub1[,"area_km"]
var2<-Varnames[j]
df_sum_sub2<-df_merge_sub[df_merge_sub$var==var2,]
dist2<-df_sum_sub2[,"area_km"]
all<-c(dist1,dist2)
ts<-median(dist1)-median(dist2)
k<-1:length(all)
reps<-c()
for (x in 1:5000){
n<-sample(k,size=min(length(dist1),length(dist2)),replace=F)
ps1<-all[n]
ps2<-all[-n]
reps[x]<-median(ps1)-median(ps2)
}
pv<-mean(abs(reps)>=abs(ts))
b_mat[j,i]<-pv
t<-t.test(dist1,dist2)
w<-wilcox.test(dist1,dist2)
wilcox_mat[j,i]<-w$p.value
t_mat[j,i]<-t$p.value
}
}
}
temp<-melt(wilcox_mat,na.rm = T)
temp$metric<-rep("area_km",nrow(temp))
wilcox_table<-rbind(wilcox_table,temp)
temp<-melt(t_mat,na.rm = T)
temp$metric<-rep("area_km",nrow(temp))
t_table<-rbind(t_table,temp)
temp<-melt(b_mat,na.rm = T)
temp$metric<-rep("area_km",nrow(temp))
b_table<-rbind(b_table,temp)
wilcox_table$test<-rep("wilcox",nrow(wilcox_table))
t_table$test<-rep("t-test",nrow(t_table))
b_table$test<-rep("permutation",nrow(b_table))
longdata_tests<-rbind(wilcox_table,t_table)
longdata_tests<-rbind(longdata_tests,b_table)
longdata_tests$test<-factor(longdata_tests$test,levels=c("t-test","wilcox","permutation"))
ncols_plot<-5
breaks<-c(0.01,seq(0.02,0.26,0.02))
labs<-breaks
labs[1:5]<-rep("",5)
labs[7:10]<-rep("",4)
labs[12:length(labs)]<-rep("",3)
cols<-colorRampPalette(c("yellow","green","blue","purple","red"))(length(breaks))
g<-ggplot(data=avgdata,aes(x=lon,y=lat)) +
coord_cartesian(expand=F) +
facet_wrap(~VAR,ncol=ncols_plot) +
geom_raster(aes(x=lon,y=lat,fill=value),interpolate = T) +
geom_contour(aes(z=value),breaks=breaks) +
scale_fill_gradientn(breaks=breaks,limits=c(min(breaks),max(breaks)),colors=cols,labels=labs)
print(g)
png("freq.png",height=300,width=1000)
print(g)
dev.off()
res_g<-ggplot(data=res,aes(x=Var1,y=Var2,fill=round(value,4))) +
geom_tile(color="white") +
scale_fill_gradient2(low="blue",high="red",mid="white",
midpoint=mm,limit=c(0,mr),name="RMSE") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 8, hjust = 1))+
coord_fixed() +
geom_text(aes(Var1, Var2, label = round(value,3)), color = "black", size = 2) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
longdata<-melt(df_summ_all[,c("duration_days","zonal_speed_kph","var")],id.vars = c("var"))
longdata2<-melt(df_merge_all[c("var","area_km")])
longdata2$value<-longdata2$value/(10^6)
longdata<-rbind(longdata,longdata2)
g1<-ggplot(data=subset(longdata,longdata$variable=="duration_days"),aes(x=value,group=var,color=var)) +
geom_density() +
#theme(legend.position = "none") +
labs(x = "Duration (days)")
print(g1)
stats_g1<-ggplot(data=subset(longdata_tests,metric=="duration_days"),aes(x=Var1,y=Var2,fill=round(value,3))) +
facet_grid(~test)+
geom_tile(color="white") +
scale_fill_gradient2(low="blue",high="red",mid="white",
midpoint=0.05,limit=c(0,1),name="p-value") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 8, hjust = 1))+
coord_fixed() +
ggtitle("Duration (days)")
print(stats_g1)
g2<-ggplot(data=subset(longdata,longdata$variable=="zonal_speed_kph"),aes(x=value,group=var,color=var)) +
geom_density() +
#theme(legend.position = "none") +
labs(x = "Zonal speed (kph)")
print(g2)
stats_g2<-ggplot(data=subset(longdata_tests,metric=="zonal_speed_kph"),aes(x=Var1,y=Var2,fill=round(value,3))) +
facet_grid(~test)+
geom_tile(color="white") +
scale_fill_gradient2(low="blue",high="red",mid="white",
midpoint=0.05,limit=c(0,1),name="p-value") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 8, hjust = 1))+
coord_fixed() +
ggtitle("Zonal speed (kph)")
print(stats_g2)
png("speed_pvalue.png",width=800,height=400)
print(stats_g2)
dev.off()
png("speed_dist.png",width=800,height=400)
print(g2)
dev.off()
